{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "# core packages\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# image packages\n",
    "import rasterio as rio\n",
    "import cv2\n",
    "\n",
    "# visualization packages\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     18
    ]
   },
   "outputs": [],
   "source": [
    "def calc_bounds(file, target_coords, length = 10): \n",
    "    with rio.open(file) as src:\n",
    "        data = src.read()\n",
    "        data = np.squeeze(data).astype(\"float32\")\n",
    "\n",
    "    lat = target_coords[0]\n",
    "    long = target_coords[1]\n",
    "   \n",
    "    lat_index = np.arange(0, data.shape[0])\n",
    "    long_index = np.arange(0, data.shape[1])\n",
    "\n",
    "    A = src.transform\n",
    "\n",
    "    ymin, xmin = rio.transform.rowcol(A, long, lat - length)\n",
    "    ymax, xmax = rio.transform.rowcol(A, long + length, lat)\n",
    "\n",
    "    return data, xmin, xmax, ymin, ymax\n",
    "\n",
    "def get_coord_string(coords):\n",
    "    if coords[0] < 0:\n",
    "        lat = str(coords[0]*-1) + \"S\" \n",
    "    else:\n",
    "        lat = str(coords[0]) + \"N\"\n",
    "    if coords[1] < 0:\n",
    "        long = str(coords[1]*-1) + \"W\"\n",
    "    else:\n",
    "        long = str(coords[1]) + \"E\"\n",
    "    coord_string = lat + long\n",
    "    \n",
    "    return coord_string\n",
    "\n",
    "def segment(file, target_coords, name):\n",
    "    data, xmin, xmax, ymin, ymax = calc_bounds(file, target_coords)\n",
    "    print(data, xmin, xmax, ymin, ymax)\n",
    "   \n",
    "    seg_data = data[ymax:ymin, xmin:xmax]\n",
    "    seg_img = Image.fromarray(seg_data)\n",
    "    \n",
    "    coords = get_coord_string(target_coords)\n",
    "    \n",
    "    path = \"../data/raw/segmented/\" + str(name) + \"_\" + str(coords) + \".tif\"\n",
    "    \n",
    "    try:\n",
    "        seg_img.save(path)\n",
    "    except:\n",
    "        print(\"Segment was too large to save\")\n",
    "    finally:\n",
    "        return seg_data\n",
    "\n",
    "def split_values(segment, default_vals, cumulative_flg):\n",
    "    res = dict()\n",
    "    for val in np.unique(segment):\n",
    "        print(\"Segmenting: {}\".format(val))\n",
    "        if val in default_vals:\n",
    "            continue\n",
    "        if cumulative_flg:\n",
    "            res[val] = (csr_matrix((segment <= val).astype(int)))\n",
    "        else:\n",
    "            res[val] = (csr_matrix((segment == val).astype(int)))\n",
    "    return res\n",
    "\n",
    "def grid_data(data, colname, grid_size, smaller):\n",
    "        \n",
    "    if smaller:\n",
    "        grid = cv2.resize(data, dsize=(grid_size, grid_size), interpolation = cv2.INTER_LINEAR)\n",
    "    else:\n",
    "        grid = cv2.resize(data, dsize=(grid_size, grid_size), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    row = np.arange(grid_size ** 2) // grid_size\n",
    "    col = np.arange(grid_size ** 2) % grid_size\n",
    "    \n",
    "    df = pd.DataFrame(index = row * grid_size + col)\n",
    "    df[\"row\"] = row\n",
    "    df[\"col\"] = col\n",
    "    \n",
    "    df[colname] = grid.flatten()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the process_data function segments data passed in according to user-specified parameters and returns a dataframe or csv file with the desired data. see parameters below.\n",
    "\n",
    "- filename: string // path to tif file (oldest data if multiple years of data) \n",
    "\n",
    "- target_coords: int tuple (latitude, longtitude) // upper left corner of desired segment \n",
    "\n",
    "- grid_size: integer // number of rows/cols in data (sqrt of number of values in dataset)\n",
    "\n",
    "- name: string // title of dataset, eg. chirps, pop, yield\n",
    "\n",
    "- years: string (default = \"\") // must input a list of years of data contained in the set if there's more than one year of data\n",
    "\n",
    "- agg_data_path: string // path to existing csv file to be merged with new data\n",
    "\n",
    "- split_vals_flg: boolean // true if we want to split data based on array values (ex. 2 = 2002)\n",
    "\n",
    "- default_vals: list // contains values that should be ignored when splitting values\n",
    "\n",
    "- cumulative flag: // used to sum all values less than equal to a value when splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def process_data(filename, name, target_coords = (-10, -60), grid_size = 500, years = None, agg_data_path = None, split_vals_flg = False, default_vals = [], cumulative_flg = False):\n",
    "    if not agg_data_path:\n",
    "        agg_df = pd.DataFrame()\n",
    "    else:\n",
    "        agg_df = pd.read_csv(agg_data_path)\n",
    "        if name in agg_df.columns:\n",
    "            print(\"here\")\n",
    "            agg_df.drop(name, axis = 1, inplace = True)\n",
    "    \n",
    "    if years:\n",
    "        year = years[0]\n",
    "\n",
    "        for i in range(len(years)):\n",
    "            file = filename.replace(str(year), str(years[i]))\n",
    "            col = str(name) + \"_\" + str(years[i])\n",
    "            data_seg = segment(file, target_coords, col)\n",
    "            if (data_seg.shape[0] < grid_size):\n",
    "                df = grid_data(data_seg, name, grid_size, True)\n",
    "            else:\n",
    "                df = grid_data(data_seg, name, grid_size, False)\n",
    "            if agg_df.empty:\n",
    "                agg_df = agg_df.append(df)\n",
    "            else:\n",
    "                agg_df = pd.merge(agg_df, df)\n",
    "    else:\n",
    "        data_seg = segment(filename, target_coords, name)\n",
    "        print(data_seg.shape)\n",
    "        # grid for split values data\n",
    "        if split_vals_flg:\n",
    "            split_values_dict = split_values(data_seg, default_vals, cumulative_flg)\n",
    "            for split_val, data in split_values_dict.items():\n",
    "                if (data.shape[0] < grid_size):\n",
    "                    df = grid_data(np.array(data.todense()).astype(\"float32\"), \"{}_{}\".format(name, split_val), grid_size, True)\n",
    "                else:\n",
    "                    df = grid_data(np.array(data.todense()).astype(\"float32\"), \"{}_{}\".format(name, split_val), grid_size, False)\n",
    "                if agg_df.empty:\n",
    "                    agg_df = agg_df.append(df)\n",
    "                else:\n",
    "                    agg_df = pd.merge(agg_df, df)\n",
    "        # grid for non split values data\n",
    "        else:\n",
    "            if (data_seg.shape[0] < grid_size):\n",
    "                df = grid_data(data_seg, name, grid_size, True)\n",
    "            else:\n",
    "                df = grid_data(data_seg, name, grid_size, False)\n",
    "            if agg_df.empty:\n",
    "                agg_df = agg_df.append(df)\n",
    "            else:\n",
    "                agg_df = pd.merge(agg_df, df)\n",
    "    #agg_df.to_csv(\"../data/processed/datasets/\" + name + \"_data\", index_label = \"id\")\n",
    "    if agg_data_path: \n",
    "        agg_df.to_csv(\"../data/processed/datasets/amazon.csv\", index = False)\n",
    "    else:\n",
    "        agg_df.to_csv(\"../data/processed/datasets/amazon.csv\", index_label = \"id\")\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SIZE = 500\n",
    "# LAT, LONG = (\"10S\", \"60W\")\n",
    "# TARGET_COORDS = (-10, -60)\n",
    "LAT, LONG = (\"0N\", \"70W\")\n",
    "TARGET_COORDS = (0, -70)\n",
    "AGG_DATA_PATH = \"../data/processed/datasets/amazon.csv\"\n",
    "\n",
    "\n",
    "chirps_path = \"../data/raw/chirps/chirps-v2.0.2001.tif\"\n",
    "chirp_years = np.arange(2001, 2019)\n",
    "\n",
    "pop = \"../data/raw/population/gpw_v4_population_count_rev11_2000_30_sec.tif\"\n",
    "pop_years = (2000, 2005, 2010, 2015)\n",
    "\n",
    "yields = \"../data/raw/yields/yield_bean.tif\"\n",
    "yield_years = (\"bean\",\"carrot\",\"cassava\",\"chickpea\",\"citrus\",\"coffee\",\"groundnut\",\"maize\",\"soybean\",\"sugarcane\",\"tomato\",\"wheat\")\n",
    "\n",
    "cropland = \"../data/raw/sa_cropland.tif\"\n",
    "pastures = \"../data/raw/sa_pasture.tif\"\n",
    "#calc slope\n",
    "elevation = \"../data/raw/elevation/srtm_25_15.tif\"\n",
    "elevation_years = (\"25_15\", \"25_16\", \"26_15\", \"26_16\")\n",
    "\n",
    "pollution_path = \"../data/raw/uvai_05.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tree_cover: values 0-100  \n",
    "datamask: 1, 2  \n",
    "defor: 0 - 18  \n",
    "wdpa: defaults: 1988, 65535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 4. 4. 6.]\n",
      " [0. 0. 0. ... 4. 7. 6.]\n",
      " [0. 0. 0. ... 4. 4. 4.]] 0 40000 40000 0\n",
      "Segment was too large to save\n",
      "(40000, 40000)\n",
      "Segmenting: 0.0\n",
      "Segmenting: 1.0\n",
      "Segmenting: 2.0\n",
      "Segmenting: 3.0\n",
      "Segmenting: 4.0\n",
      "Segmenting: 5.0\n",
      "Segmenting: 6.0\n",
      "Segmenting: 7.0\n",
      "Segmenting: 8.0\n",
      "Segmenting: 9.0\n",
      "Segmenting: 10.0\n",
      "Segmenting: 11.0\n",
      "Segmenting: 12.0\n",
      "Segmenting: 13.0\n",
      "Segmenting: 14.0\n",
      "Segmenting: 15.0\n",
      "Segmenting: 16.0\n",
      "Segmenting: 17.0\n",
      "Segmenting: 18.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>bean</th>\n",
       "      <th>carrot</th>\n",
       "      <th>cassava</th>\n",
       "      <th>chickpea</th>\n",
       "      <th>citrus</th>\n",
       "      <th>coffee</th>\n",
       "      <th>groundnut</th>\n",
       "      <th>...</th>\n",
       "      <th>defor_9.0</th>\n",
       "      <th>defor_10.0</th>\n",
       "      <th>defor_11.0</th>\n",
       "      <th>defor_12.0</th>\n",
       "      <th>defor_13.0</th>\n",
       "      <th>defor_14.0</th>\n",
       "      <th>defor_15.0</th>\n",
       "      <th>defor_16.0</th>\n",
       "      <th>defor_17.0</th>\n",
       "      <th>defor_18.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>394.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>475.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>394.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>475.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>394.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>475.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>394.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>475.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>394.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>475.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249995</td>\n",
       "      <td>249995</td>\n",
       "      <td>499</td>\n",
       "      <td>495</td>\n",
       "      <td>234.26</td>\n",
       "      <td>342.94</td>\n",
       "      <td>252.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>397.94</td>\n",
       "      <td>244.68</td>\n",
       "      <td>146.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015312</td>\n",
       "      <td>0.036562</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.011563</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018125</td>\n",
       "      <td>0.054844</td>\n",
       "      <td>0.062656</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249996</td>\n",
       "      <td>249996</td>\n",
       "      <td>499</td>\n",
       "      <td>496</td>\n",
       "      <td>234.98</td>\n",
       "      <td>344.62</td>\n",
       "      <td>253.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.62</td>\n",
       "      <td>245.64</td>\n",
       "      <td>147.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038281</td>\n",
       "      <td>0.027031</td>\n",
       "      <td>0.056875</td>\n",
       "      <td>0.064531</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>0.139219</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.102656</td>\n",
       "      <td>0.086562</td>\n",
       "      <td>0.047656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249997</td>\n",
       "      <td>249997</td>\n",
       "      <td>499</td>\n",
       "      <td>497</td>\n",
       "      <td>235.70</td>\n",
       "      <td>346.30</td>\n",
       "      <td>254.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.30</td>\n",
       "      <td>246.60</td>\n",
       "      <td>147.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021094</td>\n",
       "      <td>0.079531</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.025625</td>\n",
       "      <td>0.011563</td>\n",
       "      <td>0.160313</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.002344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249998</td>\n",
       "      <td>249998</td>\n",
       "      <td>499</td>\n",
       "      <td>498</td>\n",
       "      <td>236.00</td>\n",
       "      <td>347.00</td>\n",
       "      <td>255.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>402.00</td>\n",
       "      <td>247.00</td>\n",
       "      <td>148.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>0.016562</td>\n",
       "      <td>0.083906</td>\n",
       "      <td>0.101250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249999</td>\n",
       "      <td>249999</td>\n",
       "      <td>499</td>\n",
       "      <td>499</td>\n",
       "      <td>236.00</td>\n",
       "      <td>347.00</td>\n",
       "      <td>255.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>402.00</td>\n",
       "      <td>247.00</td>\n",
       "      <td>148.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>0.080781</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.169531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  row  col    bean  carrot  cassava  chickpea  citrus  coffee  \\\n",
       "0            0    0    0    0.00    0.00   394.00       0.0    0.00  475.00   \n",
       "1            1    0    1    0.00    0.00   394.00       0.0    0.00  475.00   \n",
       "2            2    0    2    0.00    0.00   394.10       0.0    0.00  475.10   \n",
       "3            3    0    3    0.00    0.00   394.34       0.0    0.00  475.34   \n",
       "4            4    0    4    0.00    0.00   394.58       0.0    0.00  475.58   \n",
       "...        ...  ...  ...     ...     ...      ...       ...     ...     ...   \n",
       "249995  249995  499  495  234.26  342.94   252.68       0.0  397.94  244.68   \n",
       "249996  249996  499  496  234.98  344.62   253.64       0.0  399.62  245.64   \n",
       "249997  249997  499  497  235.70  346.30   254.60       0.0  401.30  246.60   \n",
       "249998  249998  499  498  236.00  347.00   255.00       0.0  402.00  247.00   \n",
       "249999  249999  499  499  236.00  347.00   255.00       0.0  402.00  247.00   \n",
       "\n",
       "        groundnut  ...  defor_9.0  defor_10.0  defor_11.0  defor_12.0  \\\n",
       "0            0.00  ...   0.000000    0.000000    0.000000    0.000000   \n",
       "1            0.00  ...   0.000000    0.000000    0.000000    0.000000   \n",
       "2            0.00  ...   0.000000    0.000000    0.000000    0.000000   \n",
       "3            0.00  ...   0.000000    0.000000    0.000000    0.000000   \n",
       "4            0.00  ...   0.000000    0.000000    0.000000    0.000000   \n",
       "...           ...  ...        ...         ...         ...         ...   \n",
       "249995     146.84  ...   0.015312    0.036562    0.001094    0.011563   \n",
       "249996     147.32  ...   0.038281    0.027031    0.056875    0.064531   \n",
       "249997     147.80  ...   0.000000    0.021094    0.079531    0.011719   \n",
       "249998     148.00  ...   0.000000    0.011250    0.000000    0.000156   \n",
       "249999     148.00  ...   0.000000    0.031250    0.000000    0.008594   \n",
       "\n",
       "        defor_13.0  defor_14.0  defor_15.0  defor_16.0  defor_17.0  defor_18.0  \n",
       "0         0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "1         0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "2         0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "3         0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "4         0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "...            ...         ...         ...         ...         ...         ...  \n",
       "249995    0.010000    0.000000    0.018125    0.054844    0.062656    0.015000  \n",
       "249996    0.060625    0.139219    0.031562    0.102656    0.086562    0.047656  \n",
       "249997    0.002031    0.025625    0.011563    0.160313    0.101562    0.002344  \n",
       "249998    0.001406    0.006875    0.019219    0.016562    0.083906    0.101250  \n",
       "249999    0.003281    0.034375    0.080781    0.054688    0.021875    0.169531  \n",
       "\n",
       "[250000 rows x 59 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REGION = \"amazon\"\n",
    "TARGET_COORDS = (0, -70)\n",
    "AGG_DATA_PATH = \"../data/processed/datasets/amazon.csv\"\n",
    "\n",
    "# yields\n",
    "bean_path = \"../data/raw/yields/yield_bean.tif\"\n",
    "carrot_path = \"../data/raw/yields/yield_carrot.tif\"\n",
    "cassava_path = \"../data/raw/yields/yield_cassava.tif\"\n",
    "chickpea_path = \"../data/raw/yields/yield_chickpea.tif\"\n",
    "citrus_path = \"../data/raw/yields/yield_citrus.tif\"\n",
    "coffee_path = \"../data/raw/yields/yield_coffee.tif\"\n",
    "groundnut_path = \"../data/raw/yields/yield_groundnut.tif\"\n",
    "maize_path = \"../data/raw/yields/yield_maize.tif\"\n",
    "soybean_path = \"../data/raw/yields/yield_soybean.tif\"\n",
    "sugarcane_path = \"../data/raw/yields/yield_sugarcane.tif\"\n",
    "tomato_path = \"../data/raw/yields/yield_tomato.tif\"\n",
    "wheat_path = \"../data/raw/yields/yield_wheat.tif\"\n",
    "\n",
    "# amazon other\n",
    "travel_time_path = \"../data/raw/{}/travel_time.tif\".format(REGION)\n",
    "dem_path = \"../data/raw/{}/dem.tif\".format(REGION)\n",
    "tree_cover_path = \"../data/raw/{}/tree_cover.tif\".format(REGION)\n",
    "datamask_path = \"../data/raw/{}/datamask.tif\".format(REGION)\n",
    "cropland_path = \"../data/raw/{}/cropland.tif\".format(REGION)\n",
    "pasture_path = \"../data/raw/{}/pasture.tif\".format(REGION)\n",
    "\n",
    "# amazon year\n",
    "wdpa_path = \"../data/raw/{}/wdpa.tif\".format(REGION)\n",
    "loss_year_path = \"../data/raw/{}/loss_year.tif\".format(REGION)\n",
    "# AGG_DATA_PATH\n",
    "process_data(filename = loss_year_path, \n",
    "                  name = \"defor\", \n",
    "                  target_coords = TARGET_COORDS,\n",
    "                  agg_data_path = AGG_DATA_PATH,\n",
    "                  split_vals_flg = True,\n",
    "                  default_vals = [0],\n",
    "                  cumulative_flg = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# should be able to do pd.merge like below to put datasets together, but you can also include the path  \n",
    "# to an aggregate file in the function call and the function will return an aggregate dataset with the \n",
    "# new data included \n",
    "\n",
    "# pd.merge(chirps_70, pop_70).to_csv(\"../data/processed/datasets/data_0N70W.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(chirps_70, pop_70).to_csv(\"../data/processed/datasets/data_0N70W.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
