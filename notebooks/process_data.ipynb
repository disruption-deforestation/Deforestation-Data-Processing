{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "# core packages\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# image packages\n",
    "import rasterio as rio\n",
    "import cv2\n",
    "\n",
    "# visualization packages\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     18
    ]
   },
   "outputs": [],
   "source": [
    "def calc_bounds(file, target_coords, length = 10): \n",
    "    with rio.open(file) as src:\n",
    "        data = src.read()\n",
    "        data = np.squeeze(data).astype(\"float32\")\n",
    "\n",
    "    lat = target_coords[0]\n",
    "    long = target_coords[1]\n",
    "   \n",
    "    lat_index = np.arange(0, data.shape[0])\n",
    "    long_index = np.arange(0, data.shape[1])\n",
    "\n",
    "    A = src.transform\n",
    "\n",
    "    ymin, xmin = rio.transform.rowcol(A, long, lat - length)\n",
    "    ymax, xmax = rio.transform.rowcol(A, long + length, lat)\n",
    "\n",
    "    return data, xmin, xmax, ymin, ymax\n",
    "\n",
    "def get_coord_string(coords):\n",
    "    if coords[0] < 0:\n",
    "        lat = str(coords[0]*-1) + \"S\" \n",
    "    else:\n",
    "        lat = str(coords[0]) + \"N\"\n",
    "    if coords[1] < 0:\n",
    "        long = str(coords[1]*-1) + \"W\"\n",
    "    else:\n",
    "        long = str(coords[1]) + \"E\"\n",
    "    coord_string = lat + long\n",
    "    \n",
    "    return coord_string\n",
    "\n",
    "def segment(file, target_coords, name):\n",
    "    data, xmin, xmax, ymin, ymax = calc_bounds(file, target_coords)\n",
    "    print(data, xmin, xmax, ymin, ymax)\n",
    "   \n",
    "    seg_data = data[ymax:ymin, xmin:xmax]\n",
    "    seg_img = Image.fromarray(seg_data)\n",
    "    \n",
    "    coords = get_coord_string(target_coords)\n",
    "    \n",
    "    path = \"../data/raw/segmented/\" + str(name) + \"_\" + str(coords) + \".tif\"\n",
    "    \n",
    "    try:\n",
    "        seg_img.save(path)\n",
    "    except:\n",
    "        print(\"Segment was too large to save\")\n",
    "    finally:\n",
    "        return seg_data\n",
    "\n",
    "def split_values(segment, default_vals, cumulative_flg):\n",
    "    res = dict()\n",
    "    for val in np.unique(segment):\n",
    "        if val in default_vals:\n",
    "            continue\n",
    "        if cumulative_flg:\n",
    "            res[val] = (csr_matrix((segment <= val).astype(int)))\n",
    "        else:\n",
    "            res[val] = (csr_matrix((segment == val).astype(int)))\n",
    "    return res\n",
    "\n",
    "def grid_data(data, colname, grid_size, smaller):\n",
    "        \n",
    "    if smaller:\n",
    "        grid = cv2.resize(data, dsize=(grid_size, grid_size), interpolation = cv2.INTER_LINEAR)\n",
    "    else:\n",
    "        grid = cv2.resize(data, dsize=(grid_size, grid_size), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    row = np.arange(grid_size ** 2) // grid_size\n",
    "    col = np.arange(grid_size ** 2) % grid_size\n",
    "    \n",
    "    df = pd.DataFrame(index = row * grid_size + col)\n",
    "    df[\"row\"] = row\n",
    "    df[\"col\"] = col\n",
    "    \n",
    "    df[colname] = grid.flatten()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the process_data function segments data passed in according to user-specified parameters and returns a dataframe or csv file with the desired data. see parameters below.\n",
    "\n",
    "- filename: string // path to tif file (oldest data if multiple years of data) \n",
    "\n",
    "- target_coords: int tuple (latitude, longtitude) // upper left corner of desired segment \n",
    "\n",
    "- grid_size: integer // number of rows/cols in data (sqrt of number of values in dataset)\n",
    "\n",
    "- name: string // title of dataset, eg. chirps, pop, yield\n",
    "\n",
    "- years: string (default = \"\") // must input a list of years of data contained in the set if there's more than one year of data\n",
    "\n",
    "- agg_data_path: string // path to existing csv file to be merged with new data\n",
    "\n",
    "- split_vals_flg: boolean // true if we want to split data based on array values (ex. 2 = 2002)\n",
    "\n",
    "- default_vals: list // contains values that should be ignored when splitting values\n",
    "\n",
    "- cumulative flag: // used to sum all values less than equal to a value when splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def process_data(filename, name, target_coords = (-10, -60), grid_size = 500, years = \"\", agg_data_path = \"\", split_vals_flg = False, default_vals = [], cumulative_flg = False):\n",
    "    if agg_data_path == \"\":\n",
    "        agg_df = pd.DataFrame()\n",
    "    else:\n",
    "        agg_df = pd.read_csv(agg_data_path)\n",
    "    \n",
    "    if years != \"\":\n",
    "        year = years[0]\n",
    "\n",
    "        for i in range(len(years)):\n",
    "            file = filename.replace(str(year), str(years[i]))\n",
    "            col = str(name) + \"_\" + str(years[i])\n",
    "            data_seg = segment(file, target_coords, col)\n",
    "            if (data_seg.shape[0] < grid_size):\n",
    "                df = grid_data(data_seg, name, grid_size, True)\n",
    "            else:\n",
    "                df = grid_data(data_seg, name, grid_size, False)\n",
    "            if agg_df.empty:\n",
    "                agg_df = agg_df.append(df)\n",
    "            else:\n",
    "                agg_df = pd.merge(agg_df, df)\n",
    "    else:\n",
    "        data_seg = segment(filename, target_coords, name)\n",
    "        # grid for split values data\n",
    "        if split_vals_flg:\n",
    "            split_values_dict = split_values(data_seg, default_vals, cumulative_flg)\n",
    "            for split_val, data in split_values_dict.items():\n",
    "                if (data.shape[0] < grid_size):\n",
    "                    df = grid_data(np.array(data.todense()).astype(\"float32\"), \"{}_{}\".format(name, split_val), grid_size, True)\n",
    "                else:\n",
    "                    df = grid_data(np.array(data.todense()).astype(\"float32\"), \"{}_{}\".format(name, split_val), grid_size, False)\n",
    "                if agg_df.empty:\n",
    "                    agg_df = agg_df.append(df)\n",
    "                else:\n",
    "                    agg_df = pd.merge(agg_df, df)\n",
    "        # grid for non split values data\n",
    "        else:\n",
    "            if (data_seg.shape[0] < grid_size):\n",
    "                df = grid_data(data_seg, name, grid_size, True)\n",
    "            else:\n",
    "                df = grid_data(data_seg, name, grid_size, False)\n",
    "            if agg_df.empty:\n",
    "                agg_df = agg_df.append(df)\n",
    "            else:\n",
    "                agg_df = pd.merge(agg_df, df)\n",
    "    #agg_df.to_csv(\"../data/processed/datasets/\" + name + \"_data\", index_label = \"id\")\n",
    "    agg_df.to_csv(\"../data/processed/datasets/amazon.csv\", index_label = \"id\")\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SIZE = 500\n",
    "# LAT, LONG = (\"10S\", \"60W\")\n",
    "# TARGET_COORDS = (-10, -60)\n",
    "LAT, LONG = (\"0N\", \"70W\")\n",
    "TARGET_COORDS = (0, -70)\n",
    "AGG_DATA_PATH = \"../data/processed/aggregate.csv\"\n",
    "\n",
    "\n",
    "chirps_path = \"../data/raw/chirps/chirps-v2.0.2001.tif\"\n",
    "chirp_years = np.arange(2001, 2019)\n",
    "\n",
    "pop = \"../data/raw/population/gpw_v4_population_count_rev11_2000_30_sec.tif\"\n",
    "pop_years = (2000, 2005, 2010, 2015)\n",
    "\n",
    "yields = \"../data/raw/yields/yield_bean.tif\"\n",
    "yield_years = (\"bean\",\"carrot\",\"cassava\",\"chickpea\",\"citrus\",\"coffee\",\"groundnut\",\"maize\",\"soybean\",\"sugarcane\",\"tomato\",\"wheat\")\n",
    "\n",
    "cropland = \"../data/raw/sa_cropland.tif\"\n",
    "pastures = \"../data/raw/sa_pasture.tif\"\n",
    "#calc slope\n",
    "elevation = \"../data/raw/elevation/srtm_25_15.tif\"\n",
    "elevation_years = (\"25_15\", \"25_16\", \"26_15\", \"26_16\")\n",
    "\n",
    "pollution_path = \"../data/raw/uvai_05.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.4028235e+38 -3.4028235e+38 -3.4028235e+38 ... -3.4028235e+38\n",
      "  -3.4028235e+38 -3.4028235e+38]\n",
      " [-3.4028235e+38 -3.4028235e+38 -3.4028235e+38 ... -3.4028235e+38\n",
      "  -3.4028235e+38 -3.4028235e+38]\n",
      " [-3.4028235e+38 -3.4028235e+38 -3.4028235e+38 ... -3.4028235e+38\n",
      "  -3.4028235e+38 -3.4028235e+38]\n",
      " ...\n",
      " [-3.4028235e+38 -3.4028235e+38 -3.4028235e+38 ... -3.4028235e+38\n",
      "  -3.4028235e+38 -3.4028235e+38]\n",
      " [-3.4028235e+38 -3.4028235e+38 -3.4028235e+38 ... -3.4028235e+38\n",
      "  -3.4028235e+38 -3.4028235e+38]\n",
      " [-3.4028235e+38 -3.4028235e+38 -3.4028235e+38 ... -3.4028235e+38\n",
      "  -3.4028235e+38 -3.4028235e+38]] 144 264 271 151\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>bean</th>\n",
       "      <th>carrot</th>\n",
       "      <th>cassava</th>\n",
       "      <th>chickpea</th>\n",
       "      <th>citrus</th>\n",
       "      <th>coffee</th>\n",
       "      <th>groundnut</th>\n",
       "      <th>...</th>\n",
       "      <th>defor_2011</th>\n",
       "      <th>defor_2012</th>\n",
       "      <th>defor_2013</th>\n",
       "      <th>defor_2014</th>\n",
       "      <th>defor_2015</th>\n",
       "      <th>defor_2016</th>\n",
       "      <th>defor_2017</th>\n",
       "      <th>defor_2018</th>\n",
       "      <th>cropland</th>\n",
       "      <th>pasture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>342.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>363.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>248.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>378.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>311.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>433.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>482.40</td>\n",
       "      <td>251.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>489</td>\n",
       "      <td>512.06</td>\n",
       "      <td>632.88</td>\n",
       "      <td>422.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>451.20</td>\n",
       "      <td>296.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>518.40</td>\n",
       "      <td>646.38</td>\n",
       "      <td>428.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>459.02</td>\n",
       "      <td>302.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1994</td>\n",
       "      <td>2628</td>\n",
       "      <td>498</td>\n",
       "      <td>218</td>\n",
       "      <td>814.64</td>\n",
       "      <td>1390.46</td>\n",
       "      <td>868.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>978.58</td>\n",
       "      <td>506.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>2629</td>\n",
       "      <td>498</td>\n",
       "      <td>274</td>\n",
       "      <td>321.98</td>\n",
       "      <td>508.76</td>\n",
       "      <td>350.02</td>\n",
       "      <td>0</td>\n",
       "      <td>602.44</td>\n",
       "      <td>382.94</td>\n",
       "      <td>213.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>2630</td>\n",
       "      <td>498</td>\n",
       "      <td>454</td>\n",
       "      <td>533.62</td>\n",
       "      <td>919.08</td>\n",
       "      <td>431.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1245.80</td>\n",
       "      <td>755.30</td>\n",
       "      <td>283.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1997</td>\n",
       "      <td>2631</td>\n",
       "      <td>499</td>\n",
       "      <td>385</td>\n",
       "      <td>269.02</td>\n",
       "      <td>482.64</td>\n",
       "      <td>105.82</td>\n",
       "      <td>0</td>\n",
       "      <td>545.72</td>\n",
       "      <td>350.80</td>\n",
       "      <td>61.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>0.013281</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.016250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>2632</td>\n",
       "      <td>499</td>\n",
       "      <td>390</td>\n",
       "      <td>268.02</td>\n",
       "      <td>453.78</td>\n",
       "      <td>177.90</td>\n",
       "      <td>0</td>\n",
       "      <td>522.10</td>\n",
       "      <td>334.62</td>\n",
       "      <td>105.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017188</td>\n",
       "      <td>0.020313</td>\n",
       "      <td>0.023750</td>\n",
       "      <td>0.012344</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.111094</td>\n",
       "      <td>0.068906</td>\n",
       "      <td>0.020313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  row  col    bean   carrot  cassava  chickpea   citrus  coffee  \\\n",
       "0        0    0  112    0.00     0.00   342.50         0     0.00  363.00   \n",
       "1        1    0  204    0.00     0.00   248.76         0     0.00  378.18   \n",
       "2        2    0  342  311.50     0.00   433.00         0     0.00  482.40   \n",
       "3        3    0  489  512.06   632.88   422.54         0     0.00  451.20   \n",
       "4        4    0  496  518.40   646.38   428.06         0     0.00  459.02   \n",
       "...    ...  ...  ...     ...      ...      ...       ...      ...     ...   \n",
       "1994  2628  498  218  814.64  1390.46   868.82         0     0.00  978.58   \n",
       "1995  2629  498  274  321.98   508.76   350.02         0   602.44  382.94   \n",
       "1996  2630  498  454  533.62   919.08   431.46         0  1245.80  755.30   \n",
       "1997  2631  499  385  269.02   482.64   105.82         0   545.72  350.80   \n",
       "1998  2632  499  390  268.02   453.78   177.90         0   522.10  334.62   \n",
       "\n",
       "      groundnut  ...  defor_2011  defor_2012  defor_2013  defor_2014  \\\n",
       "0          0.00  ...    0.000000    0.000000    0.000000    0.000000   \n",
       "1          0.00  ...    0.000000    0.000000    0.000000    0.000000   \n",
       "2        251.30  ...    0.000000    0.000000    0.000000    0.000000   \n",
       "3        296.38  ...    0.000000    0.000000    0.000000    0.000000   \n",
       "4        302.04  ...    0.000000    0.000000    0.000000    0.000000   \n",
       "...         ...  ...         ...         ...         ...         ...   \n",
       "1994     506.82  ...    0.000000    0.000000    0.000000    0.000000   \n",
       "1995     213.30  ...    0.000000    0.000000    0.000000    0.000000   \n",
       "1996     283.20  ...    0.000000    0.000313    0.000000    0.000000   \n",
       "1997      61.50  ...    0.001875    0.002656    0.013281    0.005313   \n",
       "1998     105.36  ...    0.017188    0.020313    0.023750    0.012344   \n",
       "\n",
       "      defor_2015  defor_2016  defor_2017  defor_2018  cropland  pasture  \n",
       "0       0.000000    0.000000    0.000000    0.000000       0.0      0.0  \n",
       "1       0.000000    0.000000    0.000000    0.000000       0.0      0.0  \n",
       "2       0.000000    0.000000    0.000156    0.000000       0.0      0.0  \n",
       "3       0.000000    0.000000    0.000000    0.000000       0.0      0.0  \n",
       "4       0.000000    0.000000    0.000000    0.000000       0.0      0.0  \n",
       "...          ...         ...         ...         ...       ...      ...  \n",
       "1994    0.000000    0.000000    0.000000    0.000000       0.0      0.0  \n",
       "1995    0.000000    0.000000    0.002969    0.005625       0.0      0.0  \n",
       "1996    0.000000    0.000000    0.000000    0.000000       0.0      0.0  \n",
       "1997    0.000000    0.002188    0.016250    0.000000       0.0      0.0  \n",
       "1998    0.004375    0.111094    0.068906    0.020313       0.0      0.0  \n",
       "\n",
       "[1999 rows x 59 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yields\n",
    "bean_path = \"../data/raw/yields/yield_bean.tif\"\n",
    "carrot_path = \"../data/raw/yields/yield_carrot.tif\"\n",
    "cassava_path = \"../data/raw/yields/yield_cassava.tif\"\n",
    "chickpea_path = \"../data/raw/yields/yield_chickpea.tif\"\n",
    "citrus_path = \"../data/raw/yields/yield_citrus.tif\"\n",
    "coffee_path = \"../data/raw/yields/yield_coffee.tif\"\n",
    "groundnut_path = \"../data/raw/yields/yield_groundnut.tif\"\n",
    "maize_path = \"../data/raw/yields/yield_maize.tif\"\n",
    "soybean_path = \"../data/raw/yields/yield_soybean.tif\"\n",
    "sugarcane_path = \"../data/raw/yields/yield_sugarcane.tif\"\n",
    "tomato_path = \"../data/raw/yields/yield_tomato.tif\"\n",
    "wheat_path = \"../data/raw/yields/yield_wheat.tif\"\n",
    "\n",
    "# amazon other\n",
    "travel_time_path = \"../data/raw/amazon/travel_time.tif\"\n",
    "dem_path = \"../data/raw/amazon/dem.tif\"\n",
    "tree_cover_path = \"../data/raw/amazon/tree_cover.tif\"\n",
    "datamask_path = \"../data/raw/amazon/datamask.tif\"\n",
    "cropland_path = \"../data/raw/amazon/cropland.tif\"\n",
    "pasture_path = \"../data/raw/amazon/pasture.tif\"\n",
    "\n",
    "# amazon year\n",
    "wdpa_path = \"../data/raw/amazon/wdpa.tif\"\n",
    "loss_year_path = \"../data/raw/amazon/loss_year.tif\"\n",
    "\n",
    "TARGET_COORDS = (0, -70)\n",
    "process_data(filename = pasture_path, \n",
    "                  name = \"pasture\", \n",
    "                  target_coords = TARGET_COORDS,\n",
    "                  agg_data_path = \"../data/processed/datasets/amazon.csv\",\n",
    "                  split_vals_flg = False,\n",
    "                  default_vals = [],\n",
    "                  cumulative_flg = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# should be able to do pd.merge like below to put datasets together, but you can also include the path  \n",
    "# to an aggregate file in the function call and the function will return an aggregate dataset with the \n",
    "# new data included \n",
    "\n",
    "# pd.merge(chirps_70, pop_70).to_csv(\"../data/processed/datasets/data_0N70W.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(chirps_70, pop_70).to_csv(\"../data/processed/datasets/data_0N70W.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
